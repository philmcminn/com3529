### 1. Analysis of the Method Under Test

__Comments:__ Full automated analysis of the method under test; identifies all
branches, builds a CFG.

__Mark:__ 100

---

### 2. Test Requirement Generation

__Comments:__ Relatively simple: MCC.

__Mark:__ 55

---

### 3. Instrumentation

__Comments:__ Instrumentation is automatic. The condition outcomes are logged at
the beginning of the method, however. This is fine if you have simple methods,
where the conditions are composed of direct inputs, what happens for
intermediate values that might be assigned to variables half way through a
method? 

__Mark:__ 70

---

### 4. Test Data Generation

__Comments:__ Random test data generation for different primitive types, with
configurable bounds. 

__Mark:__ 65

---

### 5. Coverage Level Computation and Reporting

__Comments:__ Rudimentary reporting for MCC.

__Mark:__ 55

---

### 6. Test Suite Output

__Comments:__ Partial JUnit support. 

__Mark:__ 65

---

### 7. GitHub Repo and README.md

__Comments:__ The README.md provided great documentation in terms of the
examples and capability of the tool. What it did not do, however, was provide
example terminal commands for me to easily get things running myself.

__Mark:__ 65

---

### Summary

A good attempt at the project. I think you concentrated a bit more on the
automated parsing and analysis than the testing, however! 

__Overall Mark:__ 75.0% (Number of people in team: 1 -> method used: average of top 4 grades.) Please note this is a raw mark, that is, any lateness penalties have not been applied (if applicable).